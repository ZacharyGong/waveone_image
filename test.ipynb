{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "    \n",
    "        self.encoded=None\n",
    "        # channel number in the feature layer\n",
    "        f_ch = 256\n",
    "        input_len=128\n",
    "        # g function parameter\n",
    "        c = 16\n",
    "        w = 16\n",
    "        h = 16\n",
    "        g1_conv = input_len - 1 - h\n",
    "        g2_conv = (int(input_len / 2) - 1) - 1 - h\n",
    "        g3_conv = int((int(input_len / 2) - 1) / 2) - 1 - 1 - h\n",
    "        g4_deconv = h - ( int((int((int(input_len / 2) - 1) / 2) - 1) / 2) - 1 - 1 - 2)\n",
    "        g5_deconv = h - ( int((int((int((int(input_len / 2) - 1) / 2) - 1) / 2) - 1) / 2) - 1 - 1 - 2)\n",
    "        g6_deconv = h - ( int((int((int((int((int(input_len / 2) - 1) / 2) - 1) / 2) - 1) / 2) - 1) / 2) - 1 - 1)\n",
    "\n",
    "        self.down_sampler=nn.Conv2d(in_channels=3, out_channels=3, kernel_size=(4, 4),stride=(2, 2))\n",
    "\n",
    "        self.up_sampler1=nn.ConvTranspose2d(in_channels=3, out_channels=3, kernel_size=(4, 4), stride=(2, 2)) \n",
    "\n",
    "        self.up_sampler2=nn.ConvTranspose2d(in_channels=3, out_channels=3, kernel_size=(5, 5), stride=(2, 2))    \n",
    "        #ENCODER\n",
    "\n",
    "        self.en_conv_1=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=f_ch, kernel_size=(3, 3)),  # f function   \n",
    "            #32x126x126\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(in_channels=f_ch, out_channels=c, kernel_size=g1_conv)\n",
    "            #16x16x16\n",
    "        )\n",
    "\n",
    "        self.en_conv_2=nn.Sequential(\n",
    "            #3x64x64\n",
    "            nn.Conv2d(in_channels=3, out_channels=f_ch, kernel_size=(3, 3)),  # f function\n",
    "            #32x62x62\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(in_channels=f_ch, out_channels=c, kernel_size=g2_conv) # g function\n",
    "            #16x16x16\n",
    "        )\n",
    "\n",
    "        self.en_conv_3=nn.Sequential(\n",
    "            #3x32x32\n",
    "            nn.Conv2d(in_channels=3, out_channels=f_ch, kernel_size=(3, 3)),  # f function\n",
    "            #32x30x30\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(in_channels=f_ch, out_channels=c, kernel_size=g3_conv) # g function\n",
    "            #16x16x16\n",
    "        )\n",
    "\n",
    "\n",
    "        self.en_conv_4=nn.Sequential(\n",
    "            #3x16x16\n",
    "            nn.Conv2d(in_channels=3, out_channels=f_ch, kernel_size=(3, 3)),  # f function\n",
    "            #32x14x14\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(in_channels=f_ch, out_channels=c, kernel_size=g4_deconv) # g function\n",
    "            #3x16x16\n",
    "        )\n",
    "\n",
    "        self.en_conv_5=nn.Sequential(\n",
    "            #3x8x8\n",
    "            nn.Conv2d(in_channels=3, out_channels=f_ch, kernel_size=(3, 3)),  # f function\n",
    "            #32x6x6\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(in_channels=f_ch, out_channels=c, kernel_size=g5_deconv) # g function\n",
    "            #16x16x16\n",
    "        )\n",
    "\n",
    "        self.en_conv_6=nn.Sequential(\n",
    "            #3x4x4\n",
    "            nn.Conv2d(in_channels=3, out_channels=f_ch, kernel_size=(1, 1)),  # f function\n",
    "            #32x2x2\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(in_channels=f_ch, out_channels=c,kernel_size=g6_deconv) # g function\n",
    "            #16x16x16\n",
    "        )\n",
    "\n",
    "        #16x16x16\n",
    "        self.en_g_final=nn.Conv2d(in_channels=c, out_channels=c, kernel_size=(3,3))\n",
    "        #16x14x14\n",
    "\n",
    "        #DECODER\n",
    "        #16x14x14\n",
    "        self.de_g=nn.ConvTranspose2d(in_channels=c, out_channels=c, kernel_size=(3, 3))\n",
    "        #16x16x16\n",
    "\n",
    "        self.de_conv_6=nn.Sequential(\n",
    "            #g function \n",
    "            nn.Conv2d(in_channels=c, out_channels=f_ch, kernel_size=g6_deconv),\n",
    "            nn.ConvTranspose2d(in_channels=f_ch, out_channels=3, kernel_size=(1, 1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.ConvTranspose2d(in_channels=3, out_channels=3, kernel_size=(4, 4), stride=(2, 2))\n",
    "        )\n",
    "\n",
    "        self.de_conv_5=nn.Sequential(\n",
    "            #g function \n",
    "            nn.Conv2d(in_channels=c, out_channels=f_ch, kernel_size=g5_deconv),\n",
    "            nn.ConvTranspose2d(in_channels=f_ch, out_channels=3, kernel_size=(3, 3)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.ConvTranspose2d(in_channels=3, out_channels=3, kernel_size=(4, 4), stride=(2, 2))\n",
    "        )\n",
    "\n",
    "        self.de_conv_4=nn.Sequential(\n",
    "            #g function \n",
    "            nn.Conv2d(in_channels=c, out_channels=f_ch, kernel_size=g4_deconv),\n",
    "            nn.ConvTranspose2d(in_channels=f_ch, out_channels=3, kernel_size=(3, 3)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "        self.de_conv_3=nn.Sequential(\n",
    "            #g function \n",
    "            nn.ConvTranspose2d(in_channels=c, out_channels=f_ch, kernel_size=g3_conv),\n",
    "            nn.ConvTranspose2d(in_channels=f_ch, out_channels=3, kernel_size=(3, 3)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "        self.de_conv_2=nn.Sequential(\n",
    "            #g function \n",
    "            nn.ConvTranspose2d(in_channels=c, out_channels=f_ch, kernel_size=g2_conv),\n",
    "            nn.ConvTranspose2d(in_channels=f_ch, out_channels=3, kernel_size=(3, 3)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "        self.de_conv_1=nn.Sequential(\n",
    "            #g function \n",
    "            nn.ConvTranspose2d(in_channels=c, out_channels=f_ch, kernel_size=g1_conv),\n",
    "            nn.ConvTranspose2d(in_channels=f_ch, out_channels=3, kernel_size=(3, 3)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def binarizer(self, encoded, bits):\n",
    "        # 6 bits\n",
    "        encoded=encoded*(2**(bits-1))\n",
    "        encoded=torch.ceil(encoded)\n",
    "        self.encoded=encoded\n",
    "        encoded=encoded/(2**(bits-1))\n",
    "        return encoded\n",
    "\n",
    "    def decoder(self, encoded):\n",
    "        g_d=self.de_g(encoded)\n",
    "\n",
    "        f6_d=self.de_conv_6(g_d)\n",
    "        x6_d=self.up_sampler1(f6_d)\n",
    "\n",
    "        f5_d=self.de_conv_5(g_d)\n",
    "        x5_d=self.up_sampler1(x6_d+f5_d)\n",
    "\n",
    "        f4_d=self.de_conv_4(g_d)\n",
    "        x4_d=self.up_sampler1(x5_d+f4_d)\n",
    "    \n",
    "        f3_d=self.de_conv_3(g_d)\n",
    "        x3_d=self.up_sampler2(x4_d+f3_d)\n",
    "\n",
    "        f2_d=self.de_conv_2(g_d)\n",
    "        x2_d=self.up_sampler1(x3_d+f2_d)\n",
    "\n",
    "        f1_d=self.de_conv_1(g_d)\n",
    "        decoded=x2_d+f1_d\n",
    "\n",
    "        return decoded\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1=x\n",
    "        g1=self.en_conv_1(x1)\n",
    "        x2=self.down_sampler(x1)\n",
    "        g2=self.en_conv_2(x2)\n",
    "        x3=self.down_sampler(x2)\n",
    "        g3=self.en_conv_3(x3)\n",
    "        x4=self.down_sampler(x3)\n",
    "        g4=self.en_conv_4(x4)\n",
    "        x5=self.down_sampler(x4)\n",
    "        g5=self.en_conv_5(x5)\n",
    "        x6=self.down_sampler(x5)\n",
    "        g6=self.en_conv_6(x6)\n",
    "\n",
    "        encoded=g1+g2+g3+g4+g5+g6\n",
    "        encoded=self.en_g_final(encoded)\n",
    "        encoded=self.binarizer(encoded,6)\n",
    "        decoded=self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Generator()\n",
    "model=model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=torch.randn([2,3,128,128])\n",
    "input=input.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 14, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoded.cpu().detach().numpy()[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.897959183673468"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3*128*128*8/16/14/14/6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=np.zeros([3,128,128])\n",
    "input=input+100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='C://Users//zgong//Desktop/test_1.png'\n",
    "img=Image.open(path).convert('RGB')\n",
    "#print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=train_transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4039, 0.4039, 0.4078,  ..., 0.3725, 0.3686, 0.3647],\n",
       "         [0.4000, 0.4000, 0.4039,  ..., 0.3529, 0.3529, 0.3529],\n",
       "         [0.4000, 0.3961, 0.4000,  ..., 0.3490, 0.3490, 0.3490],\n",
       "         ...,\n",
       "         [0.3608, 0.3647, 0.3686,  ..., 0.3529, 0.3529, 0.3569],\n",
       "         [0.3647, 0.3647, 0.3686,  ..., 0.3451, 0.3490, 0.3490],\n",
       "         [0.3608, 0.3608, 0.3686,  ..., 0.3412, 0.3451, 0.3490]],\n",
       "\n",
       "        [[0.5294, 0.5294, 0.5294,  ..., 0.4784, 0.4745, 0.4745],\n",
       "         [0.5294, 0.5294, 0.5294,  ..., 0.4627, 0.4627, 0.4627],\n",
       "         [0.5294, 0.5255, 0.5255,  ..., 0.4627, 0.4627, 0.4627],\n",
       "         ...,\n",
       "         [0.5333, 0.5333, 0.5294,  ..., 0.5137, 0.5137, 0.5137],\n",
       "         [0.5333, 0.5333, 0.5294,  ..., 0.5098, 0.5098, 0.5098],\n",
       "         [0.5333, 0.5294, 0.5294,  ..., 0.5059, 0.5059, 0.5098]],\n",
       "\n",
       "        [[0.3490, 0.3490, 0.3569,  ..., 0.3373, 0.3294, 0.3255],\n",
       "         [0.3412, 0.3451, 0.3490,  ..., 0.3216, 0.3176, 0.3137],\n",
       "         [0.3373, 0.3412, 0.3451,  ..., 0.3176, 0.3176, 0.3176],\n",
       "         ...,\n",
       "         [0.3569, 0.3608, 0.3686,  ..., 0.3451, 0.3412, 0.3412],\n",
       "         [0.3569, 0.3608, 0.3686,  ..., 0.3373, 0.3333, 0.3333],\n",
       "         [0.3529, 0.3569, 0.3647,  ..., 0.3333, 0.3333, 0.3333]]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 16, 3, 3])\n",
      "tensor(4.6605, device='cuda:0', grad_fn=<LogBackward>)\n",
      "torch.Size([16])\n",
      "tensor(-0.0645, device='cuda:0', grad_fn=<LogBackward>)\n"
     ]
    }
   ],
   "source": [
    "l1=0\n",
    "for name, param in model.named_parameters():\n",
    "    if name=='de_g.bias' or name=='de_g.weight':\n",
    "        alpha=0.01\n",
    "        print(param.shape)\n",
    "        x = torch.ceil(32*param+0.5)/32\n",
    "        num=torch.log(torch.sum(torch.abs(x)))\n",
    "        print(num)\n",
    "        den=torch.log(torch.tensor(10).float())\n",
    "        l1+=num/den\n",
    "        regularization=alpha * l1 / (16 * 14 * 14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.8200e-06, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-9eb17f0a86e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'de_g.weight'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'generator' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "model.named_parameters('de_g.weight').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
